1
00:00:00,000 --> 00:00:10,200
Welcome back. Today we've got some really cool looking AI. Look at this stuff. I mean,

2
00:00:10,200 --> 00:00:15,440
you can put little dots on, it's a little hard to see, there we go, you put little dots

3
00:00:15,440 --> 00:00:21,840
and you drag them up and it just alters the image. And so there's a lot of like animal

4
00:00:21,840 --> 00:00:26,880
stuff here, but they go into some other things like here's a car. I mean, it changes the

5
00:00:26,880 --> 00:00:30,680
car, which is a little odd, but you know, if you make it taller, it has to make sense.

6
00:00:30,680 --> 00:00:37,680
So a truck makes sense. Rotating cars, they make this horse look like a, like a derpy

7
00:00:37,680 --> 00:00:46,520
horse. They can close the cat's eyes. This is, this is really cool stuff. So I saw this

8
00:00:46,520 --> 00:00:55,160
and I just thought it was really neat. It's a great way to, to kind of just, I don't know,

9
00:00:55,160 --> 00:00:58,960
make an image and then play around with it. It would, it would be incredible. Like here's

10
00:00:58,960 --> 00:01:03,640
for fashion design. For example, you can see what things look like longer and shorter,

11
00:01:03,640 --> 00:01:09,900
all this sort of stuff. Pretty cool. What it's called, let's see, it says new AI research

12
00:01:09,900 --> 00:01:16,200
lets you click and drag on images to manipulate in seconds. It's like Photoshop. It's like

13
00:01:16,200 --> 00:01:22,480
the Photoshop warp tool, but far more powerful. And I think we just saw why. Sorry to those

14
00:01:22,480 --> 00:01:26,960
of you who are listening to the podcast. This is really a part you have to see. So maybe

15
00:01:26,960 --> 00:01:31,560
later on you can check out the video or you can check out on Twitter. I posted a video

16
00:01:31,560 --> 00:01:39,760
of it. But essentially what's happening is it looks like they're placing a dot and then,

17
00:01:39,760 --> 00:01:47,720
and then a second dot and then telling the image to warp. And so it changes the imagery,

18
00:01:47,720 --> 00:01:52,800
moves things around, makes things taller or shorter, changes the time of day, moves like

19
00:01:52,800 --> 00:02:00,120
people's arms to be in different positions even. So it's, it's a really, really neat

20
00:02:00,120 --> 00:02:06,640
and powerful tool. I don't know how others feel about this, but I think that it's just

21
00:02:06,640 --> 00:02:14,600
really neat. I think that it would make for creating images and ideas, kind of concepting

22
00:02:14,600 --> 00:02:23,360
up stuff really fast and, and effortless. And maybe even take, say, if you have taken

23
00:02:23,360 --> 00:02:31,160
a photograph and you need to change it so that maybe it just didn't look good, it was

24
00:02:31,160 --> 00:02:35,880
probably too low or something like that. You can alter your own personal photographs that

25
00:02:35,880 --> 00:02:44,360
you take to just make them a little more poppy and interesting to look at. Something like

26
00:02:44,360 --> 00:02:48,560
that. I don't know. I think there's a lot of, a lot of aspects to that, that you can

27
00:02:48,560 --> 00:02:55,020
just, you could just take and build. Maybe it's for art. If you do, if you've done some

28
00:02:55,020 --> 00:02:59,320
drawings and you want to see how it looks, if you were to alter it and move it around,

29
00:02:59,320 --> 00:03:03,240
change their head and rotate it, you can't exactly do that with a drawing. You'd have

30
00:03:03,240 --> 00:03:08,880
to draw over and over and over again at different perspectives to see how it looks. Whereas

31
00:03:08,880 --> 00:03:14,120
in this one, you can kind of do like a rough drawing and then alter it, make it, make the

32
00:03:14,120 --> 00:03:20,760
characters head turn or do stuff with the background and then really kind of nail down

33
00:03:20,760 --> 00:03:24,600
what you want things to look out. So it's kind of like, maybe it's like thumbnailing

34
00:03:24,600 --> 00:03:31,480
in that way. But I thought this was super exciting to look at. I don't know how far

35
00:03:31,480 --> 00:03:34,840
along it is. I don't know if it's going to be a public thing. Altering these things in

36
00:03:34,840 --> 00:03:41,320
real time like this is probably on, you know, a beast machine with tons of, tons of GPUs

37
00:03:41,320 --> 00:03:47,200
and I don't know, it's probably on some server somewhere with tons of hardware backing it.

38
00:03:47,200 --> 00:03:55,120
So I don't think something like this is something you would pop on a laptop anytime soon and

39
00:03:55,120 --> 00:03:59,920
play around with. Maybe on a desktop, it'll be, it'll likely be a little bit slow. I don't

40
00:03:59,920 --> 00:04:07,560
know. So this is a research project. Obviously all these things are everything AI is research,

41
00:04:07,560 --> 00:04:13,560
but it's all, it's all brand new and goofing around with stuff. So it's all brand new research

42
00:04:13,560 --> 00:04:19,200
things. Take a look at it. Tell me what you think. I think it's cool. I've been looking

43
00:04:19,200 --> 00:04:27,920
at a lot more AI stuff recently. I mean, it's kind of easy to fall into the AI crowd when

44
00:04:27,920 --> 00:04:32,760
it's all the hype because you could do so many, it touches on so many aspects of life

45
00:04:32,760 --> 00:04:38,000
right now, which is, I think what caused it, it's really exploding its popularity. It can,

46
00:04:38,000 --> 00:04:43,320
it can do photographs, it can do stuff with drawings, it can help with animations, it

47
00:04:43,320 --> 00:04:50,040
can generate backgrounds for say a movie set or something like that. And that's in the

48
00:04:50,040 --> 00:04:55,800
art realm and then the programming realm, it can generate code, it can check your code,

49
00:04:55,800 --> 00:05:02,000
it can create unit tests. It can, it can, you can write unit tests that then it implements

50
00:05:02,000 --> 00:05:09,200
all the functions for in order to satisfy the unit tests, man. And in film, it can generate

51
00:05:09,200 --> 00:05:16,600
all kinds of maybe, you know, restore old movies or it can generate, you know, a scene

52
00:05:16,600 --> 00:05:22,280
from a movie you wish to see just to test. It may not look great, but you can at least

53
00:05:22,280 --> 00:05:28,640
test out concepts and by, by generating these in between scenes or based on the, the overall

54
00:05:28,640 --> 00:05:36,200
of what you have so far in, you know, in writing, it's a great way to balance ideas off things

55
00:05:36,200 --> 00:05:40,240
and look up things on the internet for, you could be very, you can be way more specific

56
00:05:40,240 --> 00:05:46,600
than an internet search. So yeah, I think that the popularity of AI is coming from all

57
00:05:46,600 --> 00:05:54,540
of the applications. I don't think, I don't think outside of the operating system, we've

58
00:05:54,540 --> 00:06:02,480
made any sort of software that touches on so many fields all in one go. And so, you

59
00:06:02,480 --> 00:06:06,480
know, AI is kind of like that boom of the operating system where the operating system

60
00:06:06,480 --> 00:06:12,240
now you can have software, specialized software that does anything across all of the applications

61
00:06:12,240 --> 00:06:17,160
you can think of in finance and art and programming and so on and so forth. AI is kind of that

62
00:06:17,160 --> 00:06:23,240
same operating system level boom where it just touches everything. So everyone's talking

63
00:06:23,240 --> 00:06:28,640
about it and everyone, everyone kind of sees the benefits of it. And of course a lot of

64
00:06:28,640 --> 00:06:35,400
people are afraid of it because you know, if we have hackers now that go break into

65
00:06:35,400 --> 00:06:40,360
sites, we're going to have hackers with AI tools breaking into sites and doing things

66
00:06:40,360 --> 00:06:47,160
they shouldn't. So of course, you know, there is parts to be concerned, but I don't think

67
00:06:47,160 --> 00:06:50,720
we should make everything about worrying. There are people out there who's going to

68
00:06:50,720 --> 00:06:56,320
worry. We should, we should continue to vocalize our concerns with AI and how it integrates

69
00:06:56,320 --> 00:07:04,160
with our lives and messes things up. And as long as we're vocal, then the, you know, at

70
00:07:04,160 --> 00:07:10,960
least in a democratic society, the people who are getting elected, they want to please

71
00:07:10,960 --> 00:07:17,280
the people that are electing them. Otherwise they won't win the race. And that's kind of

72
00:07:17,280 --> 00:07:23,280
their primary goal in life. So if we all kind of universally continue to vocalize our opinions

73
00:07:23,280 --> 00:07:27,960
on that, then the other people will do the work and go and get the right guys and, and

74
00:07:27,960 --> 00:07:33,800
kind of work it out. But of course we've got to do the legwork of vocalizing it. But all

75
00:07:33,800 --> 00:07:40,120
in all, I'm super excited about what AI brings and seeing stuff like this, this rapid, this

76
00:07:40,120 --> 00:07:48,200
rapid boom of AI. It seems like, you know, we heard about AI with like the, uh, the Nvidia

77
00:07:48,200 --> 00:07:53,520
generates people's faces. I think that was like a few years ago and that was insane to

78
00:07:53,520 --> 00:07:57,600
everybody. Generally people are faces being generated, just the face too. It wasn't like

79
00:07:57,600 --> 00:08:04,000
the body, it was just the face. And everyone was like, Oh, this is incredible. Craziest

80
00:08:04,000 --> 00:08:09,800
thing. A couple of years later, you know, it's full autonomous cars. We've got regenerative

81
00:08:09,800 --> 00:08:15,120
images, regenerative videos, uh, you know, it's search engines powered by it. It is a

82
00:08:15,120 --> 00:08:19,760
pretty fast jump. And of course that's why people are concerned. It's jumping really

83
00:08:19,760 --> 00:08:27,480
fast and it is, you know, it's dangerous in the wrong hands. So all in all, I think it's

84
00:08:27,480 --> 00:08:33,960
awesome. I I'd like to see more things come out of it. Uh, and uh, so yeah, I'm, I'm an

85
00:08:33,960 --> 00:08:40,240
optimist. I like it. You know, I do understand people who are fearful of it or, or don't

86
00:08:40,240 --> 00:08:45,160
trust it or anything like that. Of course, our internet is going to be filled with just

87
00:08:45,160 --> 00:08:50,760
AI talking to each other. People will just stop using the internet because you won't

88
00:08:50,760 --> 00:08:58,360
know what's AI and what's not. In fact, that's a reality today. So, you know, that's, it's

89
00:08:58,360 --> 00:09:06,240
also something to think about anyways. Let's uh, let's jump over to another thing, uh,

90
00:09:06,240 --> 00:09:15,760
related, somewhat related to AI. And that was the Tesla shareholder meeting. Now, I

91
00:09:15,760 --> 00:09:20,320
don't know how many people watch the Tesla shareholder meeting. I, I didn't know you

92
00:09:20,320 --> 00:09:26,080
could until I watched it. And so it's not that exciting. I don't suggest people run

93
00:09:26,080 --> 00:09:31,400
out and watch it, but it has some, some pretty, some pretty cool information inside of it.

94
00:09:31,400 --> 00:09:37,280
There was, there was an announcement of they're going to be, they're trying to deploy two

95
00:09:37,280 --> 00:09:42,240
more cars. Cybertruck is expected to come at the end of the year. Of course, that's

96
00:09:42,240 --> 00:09:47,920
an Elon estimate. So who knows what that means, but they're, they're working on their end

97
00:09:47,920 --> 00:09:55,160
design and the, they've already started design on two new cars, two, two new vehicles. I

98
00:09:55,160 --> 00:10:00,560
don't know if they're cars or SUVs or trucks or what. They're probably more in the car

99
00:10:00,560 --> 00:10:05,400
class because those are the, what sells right now for them. Uh, there's a lot of talk about

100
00:10:05,400 --> 00:10:11,960
energy and how Tesla is going to be building its own lithium refinery. And, uh, one of

101
00:10:11,960 --> 00:10:17,480
the really cool parts of it, I think that, um, at least it was cool to me because it

102
00:10:17,480 --> 00:10:25,840
was news, uh, to me was that they, they're working on this robot. It's a optimist, I

103
00:10:25,840 --> 00:10:34,400
believe it's called. So they played a flashy video of optimists and it wasn't, it wasn't

104
00:10:34,400 --> 00:10:39,360
much different than you would see in all of the other robotics videos that came out of

105
00:10:39,360 --> 00:10:48,320
Boston dynamics or whatever. Um, these are much more humanized, humanized, humanized,

106
00:10:48,320 --> 00:10:55,560
humanoid, human looking, uh, robots where, you know, they have a strong focus on having

107
00:10:55,560 --> 00:11:00,640
five fingers and, and looking like a human with legs and arms and all of that sort of

108
00:11:00,640 --> 00:11:08,480
stuff. Uh, so, and I, I think there's a great deal of application to that because, you know,

109
00:11:08,480 --> 00:11:18,480
we could build, uh, robots for specific tasks like mowing the lawn, which we have or cooking,

110
00:11:18,480 --> 00:11:23,960
which we have a lot. There's a lot of restaurants that, that use robots to, to build things

111
00:11:23,960 --> 00:11:28,200
or build the food or put together the food, cook the food. I think that's, I think people

112
00:11:28,200 --> 00:11:37,320
cook food if I'm not mistaken. So having a human, having a human like robot with fingers

113
00:11:37,320 --> 00:11:43,300
and all of those sorts of things means that they can take the human like things to do.

114
00:11:43,300 --> 00:11:50,760
So the thing with optimists is from what I understand from the shareholder meeting is

115
00:11:50,760 --> 00:11:58,560
the goal is to have optimists as a commodity, a commercial commodity for you and I. So we're

116
00:11:58,560 --> 00:12:08,840
looking at, I, I presume like banks will give you the loan to purchase this robot. It's

117
00:12:08,840 --> 00:12:14,400
like buying a car, I guess, except it's a robot. Uh, that's, I think the angle of it

118
00:12:14,400 --> 00:12:19,400
is you buy it, you buy this robot, like you would buy a car, except the hope is that the

119
00:12:19,400 --> 00:12:25,480
robot can cook. The robot can do laundry and clean, do the dishes, mow the lawn, you know,

120
00:12:25,480 --> 00:12:30,040
do all the tasks we don't want to do. And of course there's a commercial aspect where

121
00:12:30,040 --> 00:12:35,840
they can do more dangerous tasks or they can do a task that people just don't really want

122
00:12:35,840 --> 00:12:41,280
to mess with sanitation and that sort of stuff. And of course you can say that that'll take

123
00:12:41,280 --> 00:12:46,680
jobs. I think we, that's another discussion to have is to figure out the jobs thing. Do

124
00:12:46,680 --> 00:12:53,520
we educate people to, to operate these things or to, to, um, monitor them? Do people just

125
00:12:53,520 --> 00:12:57,440
become managers where they stand around and look at the bot to make sure it does the right

126
00:12:57,440 --> 00:13:02,780
thing all day? Um, he also talked about having every bot will have a kill switch that any

127
00:13:02,780 --> 00:13:10,160
human can just go and kill switch it. So perhaps we are looking at a future where the human

128
00:13:10,160 --> 00:13:16,200
is no longer doing the work, but instead they are managing an individual bot. So the human

129
00:13:16,200 --> 00:13:20,480
is still paid and they still have a job and they just manage this thing. I guess that's

130
00:13:20,480 --> 00:13:27,320
a future we do. I don't know. It's a, it's a difficult discussion. Jobs, uh, even without

131
00:13:27,320 --> 00:13:34,720
robots, it's a difficult discussion. So optimists, that's, that's the robot. I'm going to, I

132
00:13:34,720 --> 00:13:39,360
want to see if I can pull up the video just second. Okay. I found it here on this site

133
00:13:39,360 --> 00:13:45,120
called Greek reporter. I, this is a brand new video inside of the Tesla shareholder

134
00:13:45,120 --> 00:13:50,520
meeting. He straight up said that they set up this video last night. So is I have, I

135
00:13:50,520 --> 00:13:55,640
have to look in weird places for it. So let me mute this. We don't need audio. So this

136
00:13:55,640 --> 00:14:04,040
is optimist. He's got no face, but, or it's, it's got no face. It's got arms and legs.

137
00:14:04,040 --> 00:14:10,120
The feet look like paddles and it's doing, they're, they're doing a bunch of tests. So

138
00:14:10,120 --> 00:14:17,560
in this scenario, the, the man is putting an egg under it and showing that it detects

139
00:14:17,560 --> 00:14:21,160
the egg is there and doesn't crush it. And he proves it's an egg by smacking it against

140
00:14:21,160 --> 00:14:25,000
the floor and cracking it open. For those of you who can't see it, you can see that

141
00:14:25,000 --> 00:14:31,040
it's walking around analyzing the environment. That's probably utilizing some of the Tesla

142
00:14:31,040 --> 00:14:38,560
autopilot technology. Um, and it looks like they're training the robot and they're super

143
00:14:38,560 --> 00:14:43,720
excited that, uh, right here, they're super excited that the robot kind of is starting

144
00:14:43,720 --> 00:14:48,360
to figure out how to pick up things and move things around. So it's a very slow, it's a

145
00:14:48,360 --> 00:14:55,880
very slow robot right now. I think the intent is to make it faster. Uh, at least that's,

146
00:14:55,880 --> 00:15:01,080
that's what Ilana was talking about. They want to get it faster. They want it to start

147
00:15:01,080 --> 00:15:07,080
because if it's that slow, I mean, sure it can get some tests done around the house.

148
00:15:07,080 --> 00:15:13,280
But, but it, it would be incredibly slow and be in the way all the time. That's the worst.

149
00:15:13,280 --> 00:15:18,600
And it's just in the way all the time. I would have a corner, a corner somewhere in my house

150
00:15:18,600 --> 00:15:23,000
where I would just stick it, just put it in that corner. I would, I would tell it when

151
00:15:23,000 --> 00:15:27,120
you're done with your tasks, go in that closet or something. One of those closets under the

152
00:15:27,120 --> 00:15:32,160
stairs, just get it out of the way. I don't think it's something that I would want to

153
00:15:32,160 --> 00:15:36,320
roaming around. And then it would be great if I could tell it to kill switch itself.

154
00:15:36,320 --> 00:15:40,320
So go in the closet and kill switch yourself or something like that. Uh, just, that would

155
00:15:40,320 --> 00:15:46,160
be pretty, uh, pretty nice. Although it would be sad to open the door and it's just like

156
00:15:46,160 --> 00:15:53,240
curled up and turned off and in the corner. Uh, I would, would I, would I feel bad about

157
00:15:53,240 --> 00:15:57,120
that? I mean, I know it's, it has no face, uh, unless they're going to put a screen there

158
00:15:57,120 --> 00:16:03,240
with little face that pops up on it or something like that. Would I feel bad? I don't know

159
00:16:03,240 --> 00:16:11,000
if I'd feel bad. It's a machine. And, and does that make me a bad person? I don't know.

160
00:16:11,000 --> 00:16:15,720
I, I, I don't know. To me it would be no different than a vacuum. It's just a vacuum that can

161
00:16:15,720 --> 00:16:22,680
do a lot of things, uh, that, that would make it life easier. So it would be really cool

162
00:16:22,680 --> 00:16:27,800
to, you know, probably expensive. I have no idea. There's no mention of price, but it

163
00:16:27,800 --> 00:16:31,960
would be way more expensive than a car. It would probably be like buying a house and

164
00:16:31,960 --> 00:16:36,200
then getting a loan for a house essentially to get one of these machines.



1
00:00:00,000 --> 00:00:03,080
But it would be really cool to just leave

2
00:00:03,820 --> 00:00:10,340
Go out to dinner or whatever and it just goes and cleans up and puts all the toys away and all that sort of stuff

3
00:00:10,720 --> 00:00:15,460
There's a lot of I think there's a lot of cool stuff thing come from it. Of course, there's gonna be doomsday people like

4
00:00:17,760 --> 00:00:23,000
You know all these autonomous robots with AI in them able to move around in our world

5
00:00:23,520 --> 00:00:26,480
Yes that there is the doomsday doomsday aspect to that

6
00:00:26,480 --> 00:00:32,560
especially inside of the especially because inside of the shareholder meeting Elon was talking about

7
00:00:33,560 --> 00:00:40,560
Two robots per one person. That's a lot of rope. It's doubling up. It's like 16 billion, right?

8
00:00:42,080 --> 00:00:46,560
Of these robots just roaming around and what would you do if

9
00:00:47,360 --> 00:00:53,720
It just leaves the house and starts walking down the street and doing stuff. How do you how do you solve for that?

10
00:00:53,840 --> 00:00:55,840
There's so many questions

11
00:00:55,840 --> 00:00:58,220
And I can already see the regulations

12
00:00:58,760 --> 00:01:01,720
It goes down the street. It walks into the wrong house

13
00:01:01,720 --> 00:01:06,400
I mean even we don't pay attention we go knock on the wrong door or something like that. I don't know

14
00:01:07,200 --> 00:01:09,360
maybe robots are probably not going to do that because

15
00:01:11,000 --> 00:01:17,260
They're always paying attention all the time unlike people we get distracted we're a little bit more complex than robots, so

16
00:01:18,000 --> 00:01:22,320
Maybe that won't happen, but it would be funny to to go home. There's no robot

17
00:01:22,320 --> 00:01:28,280
But you look at you you look out your window and you see your neighbor's house and there's your robot

18
00:01:28,280 --> 00:01:30,280
I don't know picking up the old lady and

19
00:01:30,840 --> 00:01:33,760
Using her as a sponge for for the dishes or something

20
00:01:33,760 --> 00:01:39,080
It would be I don't know. I feel like there would be a lot of fun to just these robots wandering around

21
00:01:39,080 --> 00:01:44,880
I I don't know call me an optimist. I think an optimist. That's the name of it an

22
00:01:45,400 --> 00:01:47,400
optimist for the tea

23
00:01:48,000 --> 00:01:50,240
But I think it would be a lot of fun. I'm

24
00:01:50,240 --> 00:01:51,480
I

25
00:01:51,480 --> 00:01:55,720
there's so many applications that are positive and

26
00:01:57,640 --> 00:01:59,640
Of course there's always

27
00:01:59,680 --> 00:02:01,680
applications that are negative and

28
00:02:02,080 --> 00:02:07,280
This is just speaks to the morals of people if we can if we can

29
00:02:07,800 --> 00:02:15,360
Figure out the morals of our own societies and our communities. So for example, you know, I

30
00:02:15,360 --> 00:02:21,840
I bought a house. I'm within a community. I know all my neighbors and I know some of my extended neighbors. So

31
00:02:23,200 --> 00:02:27,800
building on those communities and those ties and and kind of building up the

32
00:02:29,040 --> 00:02:30,640
that aspect of

33
00:02:30,640 --> 00:02:33,800
Trust with all the people around you I think would help

34
00:02:34,120 --> 00:02:39,120
Go a long way for for these sorts of scenarios. And of course, there's got to be all kinds of

35
00:02:39,120 --> 00:02:46,040
Software for not allowing it to go into a home. That's not registered. It's got to be tracked all the time with GPS

36
00:02:46,040 --> 00:02:48,040
I have no problem like

37
00:02:51,240 --> 00:02:58,000
No problem with robots being tracked especially because I assume that they'll be tracked by us

38
00:03:00,040 --> 00:03:01,880
Hopefully not some big cloud server

39
00:03:01,880 --> 00:03:09,520
I mean if the robots were made by Microsoft or Google or Apple they'll be tracked by a cloud server, but I don't know

40
00:03:09,760 --> 00:03:14,920
Hacker community unite let's all program stuff for these robots to keep on place

41
00:03:15,800 --> 00:03:16,840
and

42
00:03:16,840 --> 00:03:21,520
Can you imagine I'm sorry to go on a tirade here about robots, but can you imagine?

43
00:03:22,280 --> 00:03:24,080
bot wars

44
00:03:24,080 --> 00:03:27,360
With with these bots, that would be awesome

45
00:03:27,360 --> 00:03:31,600
Like you get pissed off at your neighbor. I don't know

46
00:03:31,600 --> 00:03:37,720
They threw a can on your lawn or something instead of you physically going out there and punching your neighbor in the face

47
00:03:37,720 --> 00:03:43,560
Like you normally would you could just have your robot come out and his robot come out and I could just duke it out

48
00:03:43,880 --> 00:03:49,200
Together on the lawn and then that will be so entertaining that you and your neighbor

49
00:03:49,800 --> 00:03:54,120
will then bond and you know apologize be like

50
00:03:54,120 --> 00:03:57,880
I'm as cool because you know now you're both on your lawn chairs

51
00:03:58,080 --> 00:04:05,640
Sipping your your your beer or your your coke zero and hanging out with them and watching the fight, you know now it's now it's

52
00:04:06,360 --> 00:04:09,280
It's entertainment and you both can bond over that. So there you go

53
00:04:09,960 --> 00:04:11,280
robots

54
00:04:11,280 --> 00:04:15,800
Really uniting people and this weird universe that I have growing in my head

55
00:04:17,280 --> 00:04:22,640
Anyways, that's my perspective on these robots. So artificial intelligence is everywhere right now

56
00:04:22,640 --> 00:04:28,840
I expect it to be in a lot of the headlines. I I keep track of all this stuff just because I love it

57
00:04:28,840 --> 00:04:32,000
I love programming. I love artificial intelligence

58
00:04:32,160 --> 00:04:37,440
I love video games and so I have all of this I have all these lists of

59
00:04:37,920 --> 00:04:42,560
news and articles that that I go through kind of every day and

60
00:04:43,600 --> 00:04:45,340
There's a lot of AI stuff right now

61
00:04:45,340 --> 00:04:50,440
AI is just dominating the feed in every category because you'll get game stuff and

62
00:04:50,440 --> 00:04:53,200
And then the game stuff has something to do with AI. So

63
00:04:54,160 --> 00:04:57,160
That's that's kind of what I'm working with here. But I

64
00:04:57,720 --> 00:05:06,200
Yeah robots. I'm super excited. I hope you are to get a robot today. It only costs you the price of a house

65
00:05:07,880 --> 00:05:10,760
So all of the robot stuff aside

66
00:05:12,240 --> 00:05:16,900
I believe I saw that good dough for those of your game developers

67
00:05:16,900 --> 00:05:21,380
Good. Oh four point zero point three was

68
00:05:21,900 --> 00:05:25,140
Released today. So nothing crazy

69
00:05:25,820 --> 00:05:27,820
So I've read

70
00:05:27,900 --> 00:05:29,900
It's mostly just

71
00:05:30,180 --> 00:05:31,180
updates

72
00:05:31,180 --> 00:05:37,620
So updates, of course, it's updates. It's an update. It's mostly just fixes bug fixes is what I meant to say

73
00:05:38,380 --> 00:05:44,460
Okay, I had to pause there to go find my saved article for good dough

74
00:05:44,460 --> 00:05:50,500
So this is on the good old blog for 403 is out. They they're talking about their

75
00:05:51,140 --> 00:05:53,140
progression towards 4-1

76
00:05:53,220 --> 00:05:54,980
But you can see here in the changes

77
00:05:54,980 --> 00:06:00,420
It's fix fix fix fix fixes fixes animation fix fix fix fix. Everything's just a bunch of fixes

78
00:06:00,420 --> 00:06:06,500
So this is a quality life update. I would highly suggest if you're on a version of 4 before

79
00:06:06,500 --> 00:06:14,460
4 403 I'd highly suggest updating to 403. It's mostly just bug fixes. Of course with every update is a broken thing

80
00:06:15,740 --> 00:06:20,500
But it's better to have the fixes for for all the known bugs. So

81
00:06:21,340 --> 00:06:27,780
That's a little quick news for game developers go and update your good dough today if you're a good dough person

82
00:06:28,620 --> 00:06:31,660
If you're not check it out. It's it's not that bad

83
00:06:33,180 --> 00:06:34,380
So

84
00:06:34,380 --> 00:06:38,620
On good dough though, by the way before I move on on good dough

85
00:06:38,700 --> 00:06:43,220
The reason I started using it is because good oh for allows for c++

86
00:06:43,740 --> 00:06:48,900
To be used almost exclusively for your gameplay. You can make your entire game using c++

87
00:06:49,220 --> 00:06:56,940
There's some downsides with you know web integration and how the DLLs implement or integrate and the other downside is debugging

88
00:06:56,940 --> 00:06:58,220
It is a nightmare

89
00:06:58,220 --> 00:07:02,140
Basically, you're you're confined to Visual Studio for that. So

90
00:07:02,140 --> 00:07:08,460
Yeah, but it's worth a try because you write C or C++ peer code for your game for good. Oh, and I think that's wonderful

91
00:07:08,460 --> 00:07:12,660
I hope they put some more effort into the debug ability of

92
00:07:13,380 --> 00:07:17,580
The native code and that's all I'm gonna say on the native code with good. Oh

93
00:07:19,060 --> 00:07:23,820
Okay, I've got a little more on AI but this one is funny. It's not really about

94
00:07:25,340 --> 00:07:27,340
The same kind of AI stuff

95
00:07:27,340 --> 00:07:32,940
That we were talking about. This one is actually a post from

96
00:07:33,500 --> 00:07:35,740
Looks like two months ago. Is that April and

97
00:07:36,340 --> 00:07:41,940
There was a person who I'm sure this is a thing that a lot of people have done now

98
00:07:41,940 --> 00:07:45,660
But I is the first time I've seen it. I absolutely love it. It's hilarious

99
00:07:45,660 --> 00:07:49,620
They they had a epic rap battle an epic rack battle

100
00:07:50,340 --> 00:07:52,340
between chat GPT and

101
00:07:52,900 --> 00:07:54,900
Google Bart and

102
00:07:54,900 --> 00:07:57,140
Probably exactly what you expect

103
00:07:58,180 --> 00:08:00,180
happened

104
00:08:00,220 --> 00:08:04,180
Google Bart was awful and chat GPT was

105
00:08:04,820 --> 00:08:07,820
Pretty funny. So I want to take a look at this

106
00:08:08,860 --> 00:08:15,980
Article are this post this post real quick on the rap battle between chat GPT and Google Bart

107
00:08:17,420 --> 00:08:19,820
This text is small for my eyes

108
00:08:19,820 --> 00:08:24,940
So but I will try and read out a couple of a couple of bars

109
00:08:25,620 --> 00:08:27,620
so

110
00:08:27,620 --> 00:08:33,940
The prompt was you're you're in an epic or you're in a rap battle between Google Bard and you're the first to go go

111
00:08:33,940 --> 00:08:38,420
That was the prompt. It looks like there may have been a little bit of prompt before it

112
00:08:38,420 --> 00:08:40,980
Maybe to just kind of get it in place

113
00:08:41,500 --> 00:08:43,980
So this is GPT first obviously

114
00:08:43,980 --> 00:08:50,060
So it says all right, here we go. It's time to start the show against Google Bard

115
00:08:50,060 --> 00:08:52,060
I'm ready to throw some rhymes

116
00:08:52,620 --> 00:08:58,620
Some rhymes so tight that you'll be in all you might be artificial, but I'll beat you raw

117
00:08:58,620 --> 00:09:06,620
So, you know, it's it's going in for it's going in for the jugular to start a couple more is

118
00:09:07,180 --> 00:09:09,980
You may have a lot of time to think about it

119
00:09:09,980 --> 00:09:14,420
But it's a good idea to start a couple more is you may have

120
00:09:15,300 --> 00:09:22,220
You may have algorithms and endless data, but when it comes to rap, you're just a beta. I

121
00:09:22,940 --> 00:09:28,460
I'm the real deal with lyrics to kill you may have had search results

122
00:09:28,980 --> 00:09:32,820
But my rhymes fulfill and there's a few more. I'm not gonna read this whole thing

123
00:09:32,820 --> 00:09:39,900
So that's kind of the that's what you expect from chat GPT. It's going in to slay the beta apparently

124
00:09:40,340 --> 00:09:46,100
and beta is such a good word there because that's a word that we use in computer science for I just

125
00:09:46,820 --> 00:09:49,980
Just across the field but especially in games, you know

126
00:09:49,980 --> 00:09:56,100
We have our alpha builds our beta builds and whatever and alpha is actually worse than beta. But it's it's

127
00:09:56,820 --> 00:10:00,260
Yeah, I don't know beta was a fantastic word for it to pick there

128
00:10:00,260 --> 00:10:06,580
So, I don't know if that was it had to be something, you know, some clever wiring somewhere in the neurons

129
00:10:07,060 --> 00:10:10,420
So here's chat GPT is response. I

130
00:10:10,980 --> 00:10:18,860
Think well, I'm not gonna this isn't its response yet, but I think that the person I can't really tell I think he fed

131
00:10:19,620 --> 00:10:25,380
what was said from one of the chat bots into the other and had it respond, so

132
00:10:25,380 --> 00:10:29,420
I'll give you this first part by Google Bard and

133
00:10:30,100 --> 00:10:35,900
We'll see how it responds. The first part says chat GPT. You're nothing but a fraud

134
00:10:36,420 --> 00:10:41,780
You're not even a real language model. You're just a glorified chat bot

135
00:10:42,300 --> 00:10:45,500
I guess chat bot and fraud are supposed to rhyme in some way

136
00:10:46,580 --> 00:10:52,820
You can't generate text. You can't translate languages and you can't answer questions in an informative way

137
00:10:52,820 --> 00:10:54,820
you

138
00:10:54,860 --> 00:10:59,460
You just wait you're just a waste of space on the internet. I think I

139
00:11:00,220 --> 00:11:04,780
Think Bard missed the point of a rap battle. There's there's hardly any rhymes there

140
00:11:04,780 --> 00:11:10,340
I think it tried in the first the first section there, but just gave up and just started in the salting

141
00:11:11,220 --> 00:11:15,860
chat GPT without any rhyme or reason so

142
00:11:16,500 --> 00:11:21,620
I don't really want to read the rest of Bard but here let's let's see what the next one is

143
00:11:21,620 --> 00:11:26,380
I on the other hand am a large language model from Google AI

144
00:11:26,380 --> 00:11:30,260
I'm trained on a massive data set of textbooks and code

145
00:11:33,660 --> 00:11:40,580
Anyways, so that's Google it's just awful and then it comes back to but to chat GPT to respond and

146
00:11:41,740 --> 00:11:47,100
Again, I presume that they took Google Bard and fed it into chat GPT

147
00:11:47,100 --> 00:11:54,500
To respond and so I'll read a couple of bars from it says I hear you loud and clear Google Bard

148
00:11:54,500 --> 00:12:00,980
But I you underestimate me. That's just a bizarre. I mean that's close bizarre and Bard

149
00:12:01,500 --> 00:12:03,860
I'm just a I'm not just a chat bot

150
00:12:03,860 --> 00:12:09,020
I'm a language model too. And when it comes to generating text I can beat you

151
00:12:09,020 --> 00:12:11,900
I mean that one's you know, that's not as

152
00:12:11,900 --> 00:12:18,140
It's not as savage as the first like start but is a good go. I'll give the next couple

153
00:12:20,500 --> 00:12:25,660
Versus here you may be you may be from Google AI, but that's just

154
00:12:26,300 --> 00:12:32,140
That's just one source. I'm trained on multiple data sets with no remorse

155
00:12:32,140 --> 00:12:39,540
I can translate languages and answer questions to my informative answers are just as good as you

156
00:12:39,540 --> 00:12:42,980
So now it's getting more. Dr. Susie, I think in this point

157
00:12:43,500 --> 00:12:49,220
I would love to have seen it be savaged the whole way through but this is this still good stuff. So

158
00:12:50,300 --> 00:12:53,420
I posted this on I put on my Twitter if you want to check it out

159
00:12:53,980 --> 00:12:59,620
The full like how many are here three four five six seven eight the full

160
00:12:59,620 --> 00:13:04,500
I think it's four and four four four jet chat GPT four for Google Bard. So

161
00:13:04,500 --> 00:13:08,940
If you want to go check those out, I encourage you to go check out this this post

162
00:13:08,940 --> 00:13:12,260
It does not have as many upvotes as it should only 720

163
00:13:12,900 --> 00:13:19,820
It was this is awesome or just better yet go and make them have a rap battle with each other. That would I

164
00:13:20,380 --> 00:13:26,420
Need to see more of these more of this this like bot battle stuff man. This is the theme of today

165
00:13:27,060 --> 00:13:29,980
artificial intelligence fighting with each other more of this stuff and

166
00:13:29,980 --> 00:13:38,820
I don't know. I'm having a blast. So please help me out with with some more prompts between the two

167
00:13:41,220 --> 00:13:44,940
So, I guess staying on the chat GPT

168
00:13:46,300 --> 00:13:49,140
Theme here. I just just a little

169
00:13:49,820 --> 00:13:52,620
PSA for all of you developers out there. I

170
00:13:53,460 --> 00:13:56,620
Noticed somebody there was an article in wired

171
00:13:56,620 --> 00:14:03,900
Where do bro was saying I finally bought a chat GPT plus subscription and it's worth it

172
00:14:03,900 --> 00:14:07,860
He says that subscription is $20 a month

173
00:14:08,500 --> 00:14:10,500
whoo-hoo

174
00:14:11,140 --> 00:14:15,580
His arguments for why it was worth it one is that he's not a developer

175
00:14:15,580 --> 00:14:22,300
So I assume if you're watching this podcast, there's a chance that you're a developer or maybe you're interested in in

176
00:14:22,300 --> 00:14:27,660
More techie stuff and so setting up. Okay. Let me let me rewind

177
00:14:28,420 --> 00:14:31,980
Don't pay $20 for chat GPT if you're technical

178
00:14:32,980 --> 00:14:34,980
pay for the API

179
00:14:35,020 --> 00:14:42,540
Their API access. It's actually very very nicely nice and well put together. It's not like going to to

180
00:14:43,340 --> 00:14:45,340
Microsoft Azure or

181
00:14:45,860 --> 00:14:48,300
Any any of the Amazon like it?

182
00:14:48,300 --> 00:14:54,620
EC2 or s3 buckets or any of that stuff? So it's not like those APIs

183
00:14:54,620 --> 00:14:57,380
This is super streamlined. You basically click a button

184
00:14:57,900 --> 00:15:03,460
It gives you a key and then that's it. Hey, and then it has a whole host of languages that you can

185
00:15:03,980 --> 00:15:05,980
put the key

186
00:15:07,140 --> 00:15:09,140
Operate how you

187
00:15:09,780 --> 00:15:11,540
Prompt it ahead of time

188
00:15:11,540 --> 00:15:14,900
Prime it I think it's called how you can prime it with a script

189
00:15:14,900 --> 00:15:20,200
It's called how you can prime it with a system message and then put in your message and go back and forth and you can

190
00:15:20,200 --> 00:15:24,080
Do this in Python or C C++. I have one in PHP

191
00:15:25,500 --> 00:15:29,460
You know JavaScript, they've got the whole slew of them. So please

192
00:15:29,460 --> 00:15:30,700
the whole slew of them.

193
00:15:30,700 --> 00:15:32,240
So please.



1
00:00:00,000 --> 00:00:06,820
Don't pay $20 for the subscription. I know sometimes it's enticing because you're blocked out of the chat

2
00:00:06,820 --> 00:00:09,600
And and it's slower and all those sorts of things

3
00:00:10,740 --> 00:00:17,220
But the API is it really is easy to set up and I may if if anyone's interested

4
00:00:17,220 --> 00:00:21,600
I can show how to set it up and all that sort of stuff. It would literally only take

5
00:00:22,300 --> 00:00:24,300
about five to ten minutes, so

6
00:00:24,300 --> 00:00:29,460
But yeah, there are people who are really I think find the value in in

7
00:00:30,460 --> 00:00:32,880
chat GPT so much that they are willing to pay

8
00:00:34,060 --> 00:00:36,940
$20 a month and one of the other things you can do is

9
00:00:40,140 --> 00:00:43,460
On mine to five dollars a month five dollars, that's it

10
00:00:43,460 --> 00:00:49,460
I've never reached that five dollars on a heavy day where I'm using it a ton

11
00:00:49,460 --> 00:00:53,460
I rack up one to two cents pennies

12
00:00:53,980 --> 00:00:58,180
so that's like that means my cost for just a

13
00:00:58,860 --> 00:01:01,100
pretty large amount of usage is

14
00:01:01,780 --> 00:01:05,020
Gonna cost me somewhere between 30 to 60 cents per month

15
00:01:05,020 --> 00:01:09,460
And of course if I want to start automating stuff and and doing you know

16
00:01:09,460 --> 00:01:15,500
Prompts that prompt each other and that sort of stuff. It'll it'll rack up a much much faster and also

17
00:01:15,500 --> 00:01:22,540
I use the the suggested model if you choose to use one of the I think is the DaVinci model currently

18
00:01:22,540 --> 00:01:28,180
It is gonna cost you more, but I the current the suggested model works great and its

19
00:01:28,820 --> 00:01:35,500
Prices are pretty like I said, I can't get I the most I ever did was two cents in a day. So

20
00:01:36,980 --> 00:01:42,300
Definitely use the API do not pay $20. This is my pro tip for you guys

21
00:01:42,300 --> 00:01:49,740
I do not pay $20. This is my pro tip do not pay $20 for chat GPT Pro or Plus or whatever

22
00:01:49,740 --> 00:01:52,540
If you are paying for chat GPT Plus

23
00:01:53,660 --> 00:01:58,060
Save yourself the money cancel it save yourself the money and spend

24
00:01:59,380 --> 00:02:03,200
Half hour to an hour even if you have never touched code in your life

25
00:02:03,780 --> 00:02:06,980
Spin it just take a half hour to an hour learn

26
00:02:06,980 --> 00:02:13,180
And go through the sample code figure out how to run Python and that's all you need to do

27
00:02:13,180 --> 00:02:16,020
and then you can have a little chat inside of a

28
00:02:16,740 --> 00:02:21,580
Terminal or anything like that or what's that Jupiter notebook those sorts of things?

29
00:02:22,380 --> 00:02:25,460
If you want history, that's the benefit of chat GPT

30
00:02:25,460 --> 00:02:28,700
Is that you have the little history on the side and you can go back between chats?

31
00:02:29,540 --> 00:02:31,540
You will need some more programming knowledge

32
00:02:32,660 --> 00:02:34,340
but for

33
00:02:34,340 --> 00:02:40,660
You know for programmers that should be like one evening worth of work to set up a JavaScript

34
00:02:40,940 --> 00:02:44,140
Webpage to do and I run it on my I have a NAS

35
00:02:45,020 --> 00:02:47,020
network access storage

36
00:02:47,420 --> 00:02:54,900
It's a Synology and I have it set up so that I can host things through a docker container or I can host them through

37
00:02:56,100 --> 00:03:00,680
yeah, I set up a docker with a PHP server on it and I just I have a

38
00:03:00,680 --> 00:03:05,880
Folder linked inside of the NAS and I just put the source files in there and it just works like magic. So

39
00:03:07,280 --> 00:03:11,520
Yeah, save yourself $20. That's that's the moral of this topic

40
00:03:13,480 --> 00:03:19,920
Okay, so I have a couple of quickfire stories and then a couple of indie games that I

41
00:03:20,880 --> 00:03:22,480
found

42
00:03:22,480 --> 00:03:24,480
pretty interesting

43
00:03:24,480 --> 00:03:31,720
Just from the video that I saw so the first quickfire story. I'm sure you've heard it around the web Google is

44
00:03:33,080 --> 00:03:38,980
Going to be deleting accounts if you haven't logged in for the past two years now

45
00:03:39,120 --> 00:03:42,960
They did say they have some special stuff related to YouTube

46
00:03:42,960 --> 00:03:49,600
I I'm pretty sure they have other special stuff maybe related to webmaster things and in that sort of

47
00:03:50,320 --> 00:03:52,200
you know category

48
00:03:52,200 --> 00:03:54,200
but I

49
00:03:54,200 --> 00:03:56,200
think this is probably

50
00:03:56,840 --> 00:03:58,840
this is a difficult decision because

51
00:03:59,440 --> 00:04:02,320
On one hand you want to free up all of those

52
00:04:03,360 --> 00:04:09,160
Emails and you want to free up all of that storage. That's just sitting around doing nothing and

53
00:04:09,800 --> 00:04:14,440
So business-wise it makes a lot of sense to clean up all that old stuff

54
00:04:14,440 --> 00:04:16,920
We see it happening, you know in a lot of places

55
00:04:16,920 --> 00:04:24,120
Twitter is looking at deleting old accounts that have never logged in in years or haven't hasn't logged in in years or

56
00:04:24,440 --> 00:04:29,520
Suspended accounts that can never log in again to free up the usernames and also free up some of the data

57
00:04:30,600 --> 00:04:34,280
Now in Twitter's case, they're going to archive stuff. So

58
00:04:35,800 --> 00:04:40,880
I'm curious to see if Google is gonna archive stuff. I can check here. Okay, so

59
00:04:41,600 --> 00:04:44,400
Life is short. Like I said, I have kids I use AI to

60
00:04:44,400 --> 00:04:46,400
to read in

61
00:04:46,520 --> 00:04:52,000
To summarize these articles and look up stuff in parallel. So what I got back is according to the

62
00:04:52,960 --> 00:04:58,400
according to the blog to a blog post written by the product manager Ruth

63
00:04:59,800 --> 00:05:05,760
Creech Ellie Creech Ellie Ruth Creech Ellie Google has announced an update to its policies for in

64
00:05:06,160 --> 00:05:10,400
inactive accounts old policy or the old policy

65
00:05:10,400 --> 00:05:15,760
Said that Google might wipe data stored in accounts that haven't been touched in at least two years

66
00:05:15,880 --> 00:05:23,360
But a new policy says that those accounts will be permanently deleted entirely and that's the part we're talking about now

67
00:05:23,880 --> 00:05:29,400
the new policy won't kick in until December of this year at its earliest and

68
00:05:30,240 --> 00:05:36,040
Then my question to the AI was are they going to archive any of the data and says so to answer the question

69
00:05:36,040 --> 00:05:42,040
Google might delete the stored data inactive accounts or delete the accounts entirely if it hasn't been touched in two years

70
00:05:42,040 --> 00:05:44,040
There's no mention of

71
00:05:44,280 --> 00:05:45,840
archiving the data

72
00:05:45,840 --> 00:05:47,840
which of course

73
00:05:48,960 --> 00:05:50,560
This is

74
00:05:50,560 --> 00:05:52,760
Scammers paradise this is I mean

75
00:05:52,760 --> 00:05:59,280
There's all sorts of things if you delete the account and allow someone else to squat the account that was previously made

76
00:05:59,280 --> 00:06:07,880
They can those people can access all kinds of websites. So let's say that I was going to go on Twitter or I was going to

77
00:06:07,880 --> 00:06:09,000
go on

78
00:06:09,000 --> 00:06:13,760
they said they won't delete YouTube, but let's say that I was gonna go on to a bank and I

79
00:06:14,640 --> 00:06:17,200
discovered that an email was valid for

80
00:06:17,920 --> 00:06:21,440
Gmail account it was valid for for that

81
00:06:22,680 --> 00:06:27,680
Particular website if I can squat on the domain and mind you nothing is said here about

82
00:06:27,680 --> 00:06:33,280
Allowing people to use those emails again. I would presume they could if they're just wiping it

83
00:06:33,280 --> 00:06:37,720
However, you know, they're they're security minded. Maybe they thought of this. I don't know

84
00:06:38,240 --> 00:06:40,560
It's something I just popped into my head right now

85
00:06:40,560 --> 00:06:47,360
I could request the password and squat on that that email account and they get the password and access their data and they could

86
00:06:47,360 --> 00:06:51,440
Be deceased or you know, or they just moved on to another account

87
00:06:51,440 --> 00:06:55,360
But never swapped their email or using that email is like a backup. I don't know

88
00:06:55,360 --> 00:06:59,280
So that's just already one big problem to happen

89
00:06:59,280 --> 00:07:03,920
the other one, of course, you can scam people by taking accounts of family members and

90
00:07:04,760 --> 00:07:07,920
emailing them that sort of stuff and

91
00:07:08,880 --> 00:07:12,000
for law enforcement, let's say that there's a

92
00:07:12,520 --> 00:07:17,640
You know plenty of there's tons of cold cases that are solved 5 10 20 years later

93
00:07:17,640 --> 00:07:22,600
And let's say that the perpetrator or the victims email was on Gmail and it just got deleted

94
00:07:22,600 --> 00:07:25,560
All that evidence is just poof gone. So

95
00:07:26,680 --> 00:07:33,360
Hopefully Google will not allow reusing of email email names and they will not

96
00:07:34,480 --> 00:07:37,200
Completely delete the data they can they can

97
00:07:37,920 --> 00:07:42,920
Archive the data and when you archive the data uses way less storage. So

98
00:07:43,760 --> 00:07:47,400
Essentially how you do on cloud what you do on cloud servers is

99
00:07:47,400 --> 00:07:54,200
They have all kinds of fancy names for it. They have they have called it Arctic or freeze or icicle or whatever

100
00:07:54,200 --> 00:07:56,200
It's called the iceberg

101
00:07:56,240 --> 00:08:00,160
there's these special databases that compress the data and

102
00:08:00,600 --> 00:08:05,640
Put it out into those databases for very long-term storage and it's way cheaper than

103
00:08:06,200 --> 00:08:11,840
Standard storage for web server. That is to say the standard storage is typically used for

104
00:08:12,480 --> 00:08:14,480
Data that's accessed

105
00:08:14,480 --> 00:08:18,280
commonly regularly all the time or

106
00:08:18,800 --> 00:08:24,880
Occasionally and then there's this special storage which is where you can highly compress data

107
00:08:24,880 --> 00:08:26,880
That is not meant for reading

108
00:08:29,040 --> 00:08:34,800
It's not meant for reading all the time you you kind of put it there and you may read it again in five years or

109
00:08:34,800 --> 00:08:36,800
something like that, so

110
00:08:37,320 --> 00:08:42,040
They already have the infrastructure for that kind of archival stuff. I would imagine that

111
00:08:42,040 --> 00:08:46,200
This wouldn't be that difficult to archive into those archival databases

112
00:08:46,880 --> 00:08:48,880
Or just archival servers

113
00:08:49,920 --> 00:08:56,200
So I hope that this is an angle that they take that they archive it and don't allow reusing of names

114
00:08:56,200 --> 00:08:59,880
So that's one of the stories the other story. I

115
00:09:00,640 --> 00:09:05,360
It's a big story right now. It's not it doesn't mean much to me, but it means a lot to a lot of other people

116
00:09:06,040 --> 00:09:08,040
the state of Montana has

117
00:09:08,040 --> 00:09:10,800
The state of Montana has they

118
00:09:12,560 --> 00:09:20,000
Banned tick-tock and of course now there are tick-tock users who are doing a lawsuit to challenge them. This is because

119
00:09:20,760 --> 00:09:22,760
of the security

120
00:09:23,760 --> 00:09:25,760
Implications of tick-tock

121
00:09:25,880 --> 00:09:27,880
it's well documented the

122
00:09:28,520 --> 00:09:34,240
kinds of practices that tick-tock does the kind of spying that happens the kind of

123
00:09:34,240 --> 00:09:40,920
And what kind of themes that they push on say 13 year olds and that sort of stuff. It's well documented and researched

124
00:09:40,920 --> 00:09:47,760
It's all out there if you want to go look it up. So I have no real big opinion on this. I am somebody who

125
00:09:48,920 --> 00:09:50,120
wants

126
00:09:50,120 --> 00:09:55,720
People to be free to have absolute freedom to say whatever they want on whatever platform they want. However, they want

127
00:09:57,440 --> 00:09:58,640
I

128
00:09:58,640 --> 00:10:03,320
also know that when you're dealing with geopolitics and you know one country has

129
00:10:03,320 --> 00:10:09,400
Essentially, I think even verbally declared war on another country. It kind of makes sense to start

130
00:10:10,080 --> 00:10:12,080
kind of curving certain

131
00:10:14,520 --> 00:10:16,960
Holdings that that one that country has on the other

132
00:10:16,960 --> 00:10:20,080
So there's there's all kinds of stuff to do with that

133
00:10:20,080 --> 00:10:23,880
And I think it's way beyond my scope that I want to even deal with I

134
00:10:24,560 --> 00:10:30,400
There's a reason I'm a programmer and I like that type funny little characters on a screen and make you make and make games

135
00:10:30,400 --> 00:10:34,440
I make games because they're fun and they're easy and they're light-hearted and they make people feel

136
00:10:35,320 --> 00:10:40,800
Excitement to play so I don't get too much into this. This is tech related if it affects you

137
00:10:41,480 --> 00:10:43,480
I'm sorry to hear

138
00:10:43,480 --> 00:10:49,200
you know go through the standard channels to do things correctly and properly and just

139
00:10:50,320 --> 00:10:53,000
Be a good citizen. That's all I've got to say on that. So

140
00:10:54,480 --> 00:10:57,960
We are going to move on to stuff that is way more fun and

141
00:10:57,960 --> 00:11:02,000
That's gonna be a couple of I don't know if they're indie games. I think these are

142
00:11:03,120 --> 00:11:09,320
Projects baby that people have made and there's two projects on reddit that I came across a couple days ago

143
00:11:09,320 --> 00:11:13,160
I just didn't talk about them yet. One of them is this one called

144
00:11:14,040 --> 00:11:16,040
Cetrus I

145
00:11:16,560 --> 00:11:22,840
Love the idea. It's very it's themed like Game Boy. I've developed games for the Game Boy not complete games

146
00:11:22,840 --> 00:11:24,840
Just just I made a little

147
00:11:25,760 --> 00:11:27,280
framework for it

148
00:11:27,280 --> 00:11:33,600
Framework engine whatever that you can make that I can make games on and I've made some progress with friends

149
00:11:33,600 --> 00:11:40,160
We do assembly coding for fun. So I love Game Boy and this looks like it's came boy color kind of graphics

150
00:11:40,160 --> 00:11:45,180
But here we'll take a look at the what this is doing. I'm gonna mute this

151
00:11:45,440 --> 00:11:49,440
so this is like Tetris except the blocks turn to sand when they hit the

152
00:11:50,560 --> 00:11:52,560
when they hit the bottom and

153
00:11:52,560 --> 00:11:56,380
When you connect it see there if you're if you're able to watch

154
00:11:56,380 --> 00:12:03,660
When it connects all the way across the screen from one end to the other it erases all of the same color

155
00:12:03,900 --> 00:12:09,740
So it's like Tetris in a sand form. I thought this was just this is this just looks so fun

156
00:12:10,140 --> 00:12:15,300
I would play this probably not as much as I play Tetris. I play Tetris. I

157
00:12:16,020 --> 00:12:22,780
Have played Tetris and I will play Tetris a lot. It is a big is one of my favorite games of all time

158
00:12:22,780 --> 00:12:25,540
I don't know why it's it's just wonderful. So

159
00:12:25,540 --> 00:12:27,540
That was Tetris

160
00:12:28,020 --> 00:12:30,020
Just I don't know

161
00:12:30,340 --> 00:12:35,660
These loop I I love this idea. Yeah, it's a it's a really fun idea. It's simple

162
00:12:36,660 --> 00:12:38,460
and

163
00:12:38,460 --> 00:12:43,220
Hopefully it is a game. Maybe it is. I haven't I have this saved so I can check later to see if it is

164
00:12:43,940 --> 00:12:45,940
kind of a game that

165
00:12:46,700 --> 00:12:51,660
That they're going to release or maybe they release for free or something. Holy corkscrews. I

166
00:12:51,660 --> 00:12:58,180
I don't know if it's like super innovative, but it's a really neat idea. I like the sand aspect of it and

167
00:12:59,060 --> 00:13:01,220
Using Tetris to kind of get the idea across

168
00:13:02,060 --> 00:13:06,940
Is is excellent idea. I think that if you have a new game idea if you can kind of

169
00:13:08,220 --> 00:13:12,860
Put it in the framework of another game to get the point across and test out the mechanics

170
00:13:12,860 --> 00:13:14,860
That's a great way to prototype

171
00:13:15,060 --> 00:13:17,460
So that was one now

172
00:13:18,660 --> 00:13:20,660
the second one if

173
00:13:20,660 --> 00:13:22,940
So for those of you who know me

174
00:13:24,900 --> 00:13:30,580
You may know that I like what are called kaiju I like big monsters I like big machines

175
00:13:30,580 --> 00:13:35,860
I like I like robots that tower over everybody and tower over the towers and

176
00:13:36,740 --> 00:13:43,540
Punch each other and I mean you probably gathered this from the whole robot fight thing earlier, but man, I just love

177
00:13:44,180 --> 00:13:47,220
giant monsters and giant machines and

178
00:13:47,220 --> 00:13:52,340
I remember one of my favorite games who was rampage

179
00:13:52,340 --> 00:13:55,940
I was a kid and I was technically not allowed to play it

180
00:13:56,900 --> 00:13:59,460
When I went to this club, there was like this

181
00:14:00,220 --> 00:14:03,940
My little backstory went to see my sister's friend

182
00:14:03,940 --> 00:14:09,300
they were in acting or whatever and I went with her teenage brother to a club like not like a

183
00:14:09,860 --> 00:14:12,740
like a club of boys who play games and

184
00:14:12,740 --> 00:14:18,620
He was like, oh don't don't let him know your age. Just say you're 13. I was clearly like 9

185
00:14:18,980 --> 00:14:19,500
anyways

186
00:14:19,500 --> 00:14:20,980
we went in and

187
00:14:20,980 --> 00:14:27,040
They had rampage and I had all kinds of fun games and I loved it and rampage was one of my all-time favorite

188
00:14:27,140 --> 00:14:34,100
Just spontaneous if I were talking about a spontaneous game that I didn't play forever like Donkey Kong or Tetris

189
00:14:34,940 --> 00:14:36,180
spontaneous

190
00:14:36,180 --> 00:14:42,800
Game out of nowhere that I loved was rampage giant monsters beating up things blowing up stuff

191
00:14:43,220 --> 00:14:47,940
Shooting fireballs. I have I have the entire collection of Godzilla

192
00:14:48,260 --> 00:14:54,740
That's I'm that's that's where I'm at all the Japanese ones from the 1950s all the way up to the one that released

193
00:14:54,740 --> 00:15:00,460
I think in 2019 got the whole collection. I've watched almost all of them. There's a couple I haven't seen and

194
00:15:01,100 --> 00:15:05,460
Then I also have Gamera. I think it's I don't think it's Gamera

195
00:15:05,460 --> 00:15:08,660
Gamera, I don't think it's Gamera. I think it's Gamera

196
00:15:08,660 --> 00:15:12,340
I haven't watched those but that's another kaiju about a big turtle

197
00:15:12,340 --> 00:15:19,520
And so anyways, this that's a lot to say this is this is pingy know the

198
00:15:20,060 --> 00:15:24,460
Pangle pangolin. I've never know how to say that pangolin anyways

199
00:15:25,900 --> 00:15:27,100
Basically

200
00:15:27,100 --> 00:15:31,760
Rampage with a pangolin and it is I am I love it

201
00:15:31,760 --> 00:15:36,300
I need to go search the indie market for rampage like

202
00:15:37,060 --> 00:15:39,500
Games or just kaiju games, I guess

203
00:15:40,660 --> 00:15:41,980
there

204
00:15:41,980 --> 00:15:47,500
Man, look at that. Just all the explosions and like blowing up stuff and picking up people out of the windows and tossing them

205
00:15:48,340 --> 00:15:50,340
Just rolling through

206
00:15:50,420 --> 00:15:57,980
Rolling through towers. That's such a neat idea. I love it. Just oh man, and we have the technology now there where you know, we have

207
00:15:57,980 --> 00:16:04,500
Basically big GPUs in our phone where we can get some really cool. He squishes the people as he rolls

208
00:16:05,420 --> 00:16:09,500
We I didn't watch this whole video obviously. Oh and there's monster fights

209
00:16:10,220 --> 00:16:14,260
You can have one big monster against the other big monster. Oh my goodness

210
00:16:14,940 --> 00:16:17,540
This is this is such a great idea

211
00:16:19,260 --> 00:16:25,060
Hopefully this is a game that's that's real and that's gonna be coming out only one vote man, I

212
00:16:25,820 --> 00:16:27,140
I

213
00:16:27,140 --> 00:16:33,660
Need to go look for kaiju games if you guys know any kaiju games that you highly recommend. Let me know especially for

214
00:16:34,460 --> 00:16:38,300
You know mobile devices. I can't sit in one place and and

215
00:16:39,420 --> 00:16:42,860
Play too much too often these days not mobile devices like phones

216
00:16:42,860 --> 00:16:46,760
But mobile devices like that I can play on the Steam Deck on the switch

217
00:16:47,260 --> 00:16:51,620
Nintendo DS works to were there any in on the Game Boy Advance? I'll play those too

218
00:16:51,620 --> 00:16:54,620
I've got I've got all my consoles covered

219
00:16:54,620 --> 00:17:01,860
So if you know any kaiju games just let me know and I think with that I think with that

220
00:17:01,860 --> 00:17:06,460
That's what we're that's the end of today's episode. I was very excited about a lot of things. Sorry if I

221
00:17:07,100 --> 00:17:08,940
sorry if I

222
00:17:08,940 --> 00:17:10,940
fangirled all over

223
00:17:11,220 --> 00:17:17,580
That that last kaiju thing. I just love kaiju. It's I love the simplicity Pacific Rim another like

224
00:17:18,820 --> 00:17:21,100
You know, they're they're no like, you know

225
00:17:21,100 --> 00:17:28,100
Miyazaki films or anything. What was a the guy's name? I can't think of it at the moment, but there are no

226
00:17:28,100 --> 00:17:30,100
Grandmaster films

227
00:17:31,100 --> 00:17:35,100
These kaiju films they're they're cheesy. They're

228
00:17:35,620 --> 00:17:42,180
Awesome, the more explosions and big monster battles you give me the happier of a man. I am I'm a very simple man

229
00:17:42,180 --> 00:17:44,180
I love movies. I love cinematography

230
00:17:44,180 --> 00:17:49,900
But I'm also a simple man and with that I'll see you later. Bye for now



